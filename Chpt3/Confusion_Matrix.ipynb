{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consufion Matrices\n",
    "\n",
    "Print the confusion matrices nicely then try random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, \n",
    "                            classification_report, multilabel_confusion_matrix, mean_squared_error, mean_absolute_error)\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob, json, os\n",
    "from tabulate import tabulate\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995 ['Data_20120330_01_004_0', 'Data_20120330_01_004_1', 'Data_20120330_01_004_10', 'Data_20120330_01_004_11', 'Data_20120330_01_004_12']\n",
      "634\n",
      "634\n",
      "[0 1 2 3 4] [ 20   6  22 120 466] [0.03154574 0.00946372 0.03470032 0.18927445 0.73501577]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7350157728706624"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load file names and labels for the processed data\n",
    "data_folder_prefix = \"../Seg_Featured_Data_Updated/Seg_Featured_\"\n",
    "\n",
    "with open(\"../data_labels.json\", 'r') as json_file:\n",
    "    label_dict = json.load(json_file)\n",
    "\n",
    "data_files = glob.glob(\"../Seg_Featured_Data_Updated/Seg_Featured_*\")\n",
    "avalible_files=[]\n",
    "for fl in data_files:\n",
    "    avalible_files.append(fl[len(\"../Seg_Featured_Data_Updated\\Seg_Featured_\"):-len(\".npy\")])\n",
    "\n",
    "print(len(avalible_files), avalible_files[:5])\n",
    "# print(avalible_files[0], list(label_dict.keys())[0])\n",
    "\n",
    "\n",
    "file_names = set.intersection(set(avalible_files), set(list(label_dict.keys())))\n",
    "print(len(file_names))\n",
    "\n",
    "labels = []\n",
    "for fl in file_names:\n",
    "    labels.append(label_dict[fl])\n",
    "print(len(labels))\n",
    "\n",
    "files = [data_folder_prefix+x+\".npy\" for x in file_names]\n",
    "\n",
    "ct, values = np.unique(labels, return_counts=True)\n",
    "print(ct, values, values/values.sum())\n",
    "\n",
    "pred = [4]* len(files)\n",
    "accuracy_score(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2229,)\n",
      "(635, 2229)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((634, 2229), 634)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len([0]*576+[0]*576+[0]*576+[0]*250*2+[0]*1) \n",
    "flattened_test_load = np.zeros((max_len, ))\n",
    "print(flattened_test_load.shape)\n",
    "\n",
    "for fl in files:\n",
    "    data = np.load(fl, None, allow_pickle=True)\n",
    "    flattened_test_load = np.vstack((flattened_test_load, data))\n",
    "\n",
    "print(flattened_test_load.shape)\n",
    "\n",
    "flattened_data = flattened_test_load[1:,:]\n",
    "flattened_data.shape, len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507 127 507 127\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattened_data, labels, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [ 4  1  6 27 89] [0.03149606 0.00787402 0.04724409 0.21259843 0.7007874 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.031496062992125984,\n",
       " 1: 0.007874015748031496,\n",
       " 2: 0.047244094488188976,\n",
       " 3: 0.2125984251968504,\n",
       " 4: 0.7007874015748031}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct, values = np.unique(y_test, return_counts=True)\n",
    "test_weights = values/values.sum()\n",
    "print(ct, values, values/values.sum())\n",
    "class_weight_dict = {}\n",
    "for c in ct:\n",
    "    class_weight_dict[c] = test_weights[c]\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |        0 |   1 |        2 |       3 |       4 |\n",
      "|----|----------|-----|----------|---------|---------|\n",
      "|  0 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  1 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  2 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  3 | 0.940741 |   0 | 0        | 2.82222 | 21.637  |\n",
      "|  4 | 0        |   0 | 0.285393 | 1.42697 | 23.6876 |\n",
      "\n",
      "\n",
      "|    |   0 |   1 |   2 |   3 |   4 |\n",
      "|----|-----|-----|-----|-----|-----|\n",
      "|  0 |   0 |   0 |   0 |   0 |   4 |\n",
      "|  1 |   0 |   0 |   0 |   0 |   1 |\n",
      "|  2 |   0 |   0 |   0 |   0 |   6 |\n",
      "|  3 |   1 |   0 |   0 |   3 |  23 |\n",
      "|  4 |   0 |   0 |   1 |   5 |  83 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/RF/clf_0.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/RF/clf_0.pkl', 'rb') as f:\n",
    "        clf0 = pickle.load(f)\n",
    "else:\n",
    "    # create Random Forest\n",
    "    clf0 = RandomForestClassifier(\n",
    "        n_estimators=500, \n",
    "        max_depth=None,\n",
    "        min_samples_split=10, \n",
    "        class_weight='balanced'\n",
    "        )\n",
    "\n",
    "    clf0.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/RF/clf_0.pkl','wb') as f:\n",
    "        pickle.dump(clf0,f)\n",
    "\n",
    "pred_labels = clf0.predict(X_test)\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_labels, sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, clf0.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesnt classify anything as 0-3\n",
    "\n",
    "# if(os.path.exists('../Models/RF/clf_0_w.pkl')):\n",
    "#     # Load the random forest\n",
    "#     with open('../Models/RF/clf_0_w.pkl', 'rb') as f:\n",
    "#         clf_0_w = pickle.load(f)\n",
    "# else:\n",
    "#     # create Random Forest\n",
    "#     clf_0_w = RandomForestClassifier(\n",
    "#         n_estimators=500, \n",
    "#         max_depth=None,\n",
    "#         min_samples_split=10, \n",
    "#         class_weight=class_weight_dict\n",
    "#         )\n",
    "\n",
    "#     clf_0_w.fit(X_train, y_train)\n",
    "\n",
    "#     with open('../Models/RF/clf_0_w.pkl','wb') as f:\n",
    "#         pickle.dump(clf_0_w,f)\n",
    "\n",
    "# print(\"X= Pred, Y= True\")\n",
    "# print(tabulate(confusion_matrix(y_test, clf_0_w.predict(X_test), sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "# print(\"\\n\")\n",
    "# print(tabulate(confusion_matrix(y_test, clf_0_w.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |        0 |   1 |        2 |       3 |       4 |\n",
      "|----|----------|-----|----------|---------|---------|\n",
      "|  0 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  1 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  2 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  3 | 0.940741 |   0 | 0        | 1.88148 | 22.5778 |\n",
      "|  4 | 0        |   0 | 0.285393 | 1.42697 | 23.6876 |\n",
      "\n",
      "\n",
      "|    |   0 |   1 |   2 |   3 |   4 |\n",
      "|----|-----|-----|-----|-----|-----|\n",
      "|  0 |   0 |   0 |   0 |   0 |   4 |\n",
      "|  1 |   0 |   0 |   0 |   0 |   1 |\n",
      "|  2 |   0 |   0 |   0 |   0 |   6 |\n",
      "|  3 |   1 |   0 |   0 |   2 |  24 |\n",
      "|  4 |   0 |   0 |   1 |   5 |  83 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/RF/clf_1.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/RF/clf_1.pkl', 'rb') as f:\n",
    "        clf_1 = pickle.load(f)\n",
    "else:\n",
    "    # Create rf model\n",
    "    clf_1 = RandomForestClassifier(\n",
    "        n_estimators=1000, max_depth=None,\n",
    "        min_samples_split=10,\n",
    "        class_weight='balanced'\n",
    "        )\n",
    "\n",
    "    clf_1.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/RF/clf_1.pkl','wb') as f:\n",
    "        pickle.dump(clf_1,f)\n",
    "\n",
    "pred_labels_1 = clf_1.predict(X_test)\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_labels_1, sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, clf_1.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507 127 507 127\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattened_data, labels, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesnt classify anything as 0-3\n",
    "\n",
    "# if(os.path.exists('../Models/RF/clf_1_w.pkl')):\n",
    "#     # Load the random forest\n",
    "#     with open('../Models/RF/clf_1_w.pkl', 'rb') as f:\n",
    "#         clf_1_w = pickle.load(f)\n",
    "# else:\n",
    "#     # create Random Forest\n",
    "#     clf_1_w = RandomForestClassifier(\n",
    "#         n_estimators=500, \n",
    "#         max_depth=None,\n",
    "#         min_samples_split=10, \n",
    "#         class_weight=class_weight_dict\n",
    "#         )\n",
    "\n",
    "#     clf_1_w.fit(X_train, y_train)\n",
    "\n",
    "#     with open('../Models/RF/clf_1_w.pkl','wb') as f:\n",
    "#         pickle.dump(clf_1_w,f)\n",
    "\n",
    "# print(\"X= Pred, Y= True\")\n",
    "# print(tabulate(confusion_matrix(y_test, clf_1_w.predict(X_test), sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "# print(\"\\n\")\n",
    "# print(tabulate(confusion_matrix(y_test, clf_1_w.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |        0 |   1 |        2 |       3 |       4 |\n",
      "|----|----------|-----|----------|---------|---------|\n",
      "|  0 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  1 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  2 | 0        |   0 | 0        | 0       | 25.4    |\n",
      "|  3 | 0.940741 |   0 | 0        | 2.82222 | 21.637  |\n",
      "|  4 | 0.285393 |   0 | 0.285393 | 1.99775 | 22.8315 |\n",
      "\n",
      "\n",
      "|    |   0 |   1 |   2 |   3 |   4 |\n",
      "|----|-----|-----|-----|-----|-----|\n",
      "|  0 |   0 |   0 |   0 |   0 |   4 |\n",
      "|  1 |   0 |   0 |   0 |   0 |   1 |\n",
      "|  2 |   0 |   0 |   0 |   0 |   6 |\n",
      "|  3 |   1 |   0 |   0 |   2 |  24 |\n",
      "|  4 |   0 |   0 |   1 |   5 |  83 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/RF/clf_2.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/RF/clf_2.pkl', 'rb') as f:\n",
    "        clf_2 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # create Random Forest\n",
    "    clf_2 = RandomForestClassifier(\n",
    "        n_estimators=1000, max_depth=None,\n",
    "        min_samples_split=20,\n",
    "        class_weight='balanced'\n",
    "        )\n",
    "\n",
    "    clf_2.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/RF/clf_2.pkl','wb') as f:\n",
    "        pickle.dump(clf_2,f)\n",
    "\n",
    "pred_labels_2 = clf_2.predict(X_test)\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_labels_2, sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, clf_1.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |        0 |   1 |        2 |       3 |      4 |\n",
      "|----|----------|-----|----------|---------|--------|\n",
      "|  0 | 0        |   0 | 0        | 0       | 25.4   |\n",
      "|  1 | 0        |   0 | 0        | 0       | 25.4   |\n",
      "|  2 | 0        |   0 | 0        | 0       | 25.4   |\n",
      "|  3 | 0.940741 |   0 | 0        | 2.82222 | 21.637 |\n",
      "|  4 | 0.285393 |   0 | 0.285393 | 0.85618 | 23.973 |\n",
      "\n",
      "\n",
      "|    |   0 |   1 |   2 |   3 |   4 |\n",
      "|----|-----|-----|-----|-----|-----|\n",
      "|  0 |   0 |   0 |   0 |   0 |   4 |\n",
      "|  1 |   0 |   0 |   0 |   0 |   1 |\n",
      "|  2 |   0 |   0 |   0 |   0 |   6 |\n",
      "|  3 |   1 |   0 |   0 |   2 |  24 |\n",
      "|  4 |   0 |   0 |   1 |   5 |  83 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/RF/clf_3.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/RF/clf_3.pkl', 'rb') as f:\n",
    "        clf_3 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # create Random Forest\n",
    "    clf_3 = RandomForestClassifier(\n",
    "        n_estimators=10000, max_depth=5000,\n",
    "        min_samples_split=10,\n",
    "        class_weight='balanced'\n",
    "        )\n",
    "\n",
    "    clf_3.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/RF/clf_3.pkl','wb') as f:\n",
    "        pickle.dump(clf_3,f)\n",
    "\n",
    "\n",
    "pred_labels_3 = clf_3.predict(X_test)\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_labels_3, sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, clf_1.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |        0 |   1 |   2 |       3 |       4 |\n",
      "|----|----------|-----|-----|---------|---------|\n",
      "|  0 | 0        |   0 |   0 | 0       | 25.4    |\n",
      "|  1 | 0        |   0 |   0 | 0       | 25.4    |\n",
      "|  2 | 4.23333  |   0 |   0 | 0       | 21.1667 |\n",
      "|  3 | 0.940741 |   0 |   0 | 1.88148 | 22.5778 |\n",
      "|  4 | 0        |   0 |   0 | 1.14157 | 24.2584 |\n",
      "\n",
      "\n",
      "|    |   0 |   1 |   2 |   3 |   4 |\n",
      "|----|-----|-----|-----|-----|-----|\n",
      "|  0 |   0 |   0 |   0 |   0 |   4 |\n",
      "|  1 |   0 |   0 |   0 |   0 |   1 |\n",
      "|  2 |   0 |   0 |   0 |   0 |   6 |\n",
      "|  3 |   1 |   0 |   0 |   2 |  24 |\n",
      "|  4 |   0 |   0 |   1 |   5 |  83 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/RF/clf_4.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/RF/clf_4.pkl', 'rb') as f:\n",
    "        clf_4 = pickle.load(f)\n",
    "else:\n",
    "    # create Random Forest\n",
    "    clf_4 = RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        class_weight='balanced'\n",
    "        )\n",
    "\n",
    "    clf_4.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/RF/clf_4.pkl','wb') as f:\n",
    "        pickle.dump(clf_4,f)\n",
    "\n",
    "pred_labels_4 = clf_4.predict(X_test)\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_labels_4, sample_weight=compute_sample_weight('balanced', y_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, clf_1.predict(X_test)), headers=[0,1,2,3,4],showindex=\"always\", tablefmt=\"github\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |     2.0 |      3.0 |     4.0 |      5.0 |      6.0 |\n",
      "|----|-------|-------|---------|----------|---------|----------|----------|\n",
      "|  0 |     0 |     0 | 0       | 19.05    |  6.35   | 0        |  0       |\n",
      "|  1 |     0 |     0 | 0       |  0       |  0      | 0        | 25.4     |\n",
      "|  2 |     0 |     0 | 0       |  8.46667 | 12.7    | 4.23333  |  0       |\n",
      "|  3 |     0 |     0 | 0       | 10.3481  | 12.2296 | 0.940741 |  1.88148 |\n",
      "|  4 |     0 |     0 | 0.85618 |  7.99101 | 12.5573 | 3.13933  |  0.85618 |\n",
      "|  5 |     0 |     0 | 0       |  0       |  0      | 0        |  0       |\n",
      "|  6 |     0 |     0 | 0       |  0       |  0      | 0        |  0       |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |   6.0 |\n",
      "|----|-------|-------|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     3 |     1 |     0 |     0 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |\n",
      "|  2 |     0 |     0 |     0 |     2 |     3 |     1 |     0 |\n",
      "|  3 |     0 |     0 |     0 |    11 |    13 |     1 |     2 |\n",
      "|  4 |     0 |     0 |     3 |    28 |    44 |    11 |     3 |\n",
      "|  5 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|  6 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/NN/model_0')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    model_0 = tf.keras.saving.load_model('../Models/NN/model_0')\n",
    "else:\n",
    "    # create Random Forest\n",
    "    model_0 = Sequential()\n",
    "    model_0.add(Dense(64, input_dim=2229, activation='relu'))\n",
    "    model_0.add(Dense(32, activation='relu'))\n",
    "    model_0.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model_0.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    model_0.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    tf.keras.saving.save_model(model_0, \"../Models/NN/model_0\", overwrite=True, save_format=\"tf\")\n",
    "\n",
    "pred_0 = np.rint(model_0.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_0).max()+1))\n",
    "\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_0, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_0), headers=headers,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |      2.0 |      3.0 |     4.0 |       5.0 |      6.0 |      7.0 |\n",
      "|----|-------|-------|----------|----------|---------|-----------|----------|----------|\n",
      "|  0 |     0 |     0 | 0        | 25.4     |  0      |  0        | 0        | 0        |\n",
      "|  1 |     0 |     0 | 0        |  0       |  0      | 25.4      | 0        | 0        |\n",
      "|  2 |     0 |     0 | 0        | 12.7     | 12.7    |  0        | 0        | 0        |\n",
      "|  3 |     0 |     0 | 0        | 10.3481  | 12.2296 |  0.940741 | 0.940741 | 0.940741 |\n",
      "|  4 |     0 |     0 | 0.285393 |  7.99101 | 12.5573 |  3.99551  | 0.285393 | 0.285393 |\n",
      "|  5 |     0 |     0 | 0        |  0       |  0      |  0        | 0        | 0        |\n",
      "|  6 |     0 |     0 | 0        |  0       |  0      |  0        | 0        | 0        |\n",
      "|  7 |     0 |     0 | 0        |  0       |  0      |  0        | 0        | 0        |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |   6.0 |   7.0 |\n",
      "|----|-------|-------|-------|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     4 |     0 |     0 |     0 |     0 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |\n",
      "|  2 |     0 |     0 |     0 |     3 |     3 |     0 |     0 |     0 |\n",
      "|  3 |     0 |     0 |     0 |    11 |    13 |     1 |     1 |     1 |\n",
      "|  4 |     0 |     0 |     1 |    28 |    44 |    14 |     1 |     1 |\n",
      "|  5 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|  6 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|  7 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/NN/model_1')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    model_1 = tf.keras.saving.load_model('../Models/NN/model_1')\n",
    "else:\n",
    "    # create Random Forest\n",
    "    model_1 = Sequential()\n",
    "    model_1.add(Dense(128,input_dim=2229,activation='relu'))\n",
    "    model_1.add(Dense(64,activation='relu'))\n",
    "    model_1.add(Dense(32,activation='relu'))\n",
    "    model_1.add(Dense(1,activation='linear'))\n",
    "\n",
    "    model_1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    model_1.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    tf.keras.saving.save_model(model_1, \"../Models/NN/model_1\", overwrite=True, save_format=\"tf\")\n",
    "\n",
    "pred_1 = np.rint(model_1.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_1).max()+1))\n",
    "\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_1, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_1), headers=headers,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |     2.0 |      3.0 |      4.0 |      5.0 |     6.0 |\n",
      "|----|-------|-------|---------|----------|----------|----------|---------|\n",
      "|  0 |     0 |     0 | 0       | 25.4     |  0       |  0       | 0       |\n",
      "|  1 |     0 |     0 | 0       |  0       |  0       | 25.4     | 0       |\n",
      "|  2 |     0 |     0 | 0       | 12.7     |  8.46667 |  4.23333 | 0       |\n",
      "|  3 |     0 |     0 | 0       |  8.46667 | 12.2296  |  2.82222 | 1.88148 |\n",
      "|  4 |     0 |     0 | 0.85618 |  5.99326 | 14.5551  |  2.85393 | 1.14157 |\n",
      "|  5 |     0 |     0 | 0       |  0       |  0       |  0       | 0       |\n",
      "|  6 |     0 |     0 | 0       |  0       |  0       |  0       | 0       |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |   6.0 |\n",
      "|----|-------|-------|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     4 |     0 |     0 |     0 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |\n",
      "|  2 |     0 |     0 |     0 |     3 |     2 |     1 |     0 |\n",
      "|  3 |     0 |     0 |     0 |     9 |    13 |     3 |     2 |\n",
      "|  4 |     0 |     0 |     3 |    21 |    51 |    10 |     4 |\n",
      "|  5 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|  6 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('../Models/NN/model_2')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    model_2 = tf.keras.saving.load_model('../Models/NN/model_2')\n",
    "else:\n",
    "    # create Random Forest\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(256,input_dim=2229,activation='relu'))\n",
    "    model_2.add(Dense(128,activation='relu'))\n",
    "    model_2.add(Dense(64,activation='relu'))\n",
    "    model_2.add(Dense(32,activation='relu'))\n",
    "    model_2.add(Dense(1,activation='linear'))\n",
    "\n",
    "    model_2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    model_2.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "    tf.keras.saving.save_model(model_2, \"../Models/NN/model_2\", overwrite=True, save_format=\"tf\")\n",
    "\n",
    "pred_2 = np.rint(model_2.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_2).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_2, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_2), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|   0.0 |     1.0 |      2.0 |      3.0 |     4.0 |     5.0 |      6.0 |     7.0 |     8.0 |      9.0 |\n",
      "|-------|---------|----------|----------|---------|---------|----------|---------|---------|----------|\n",
      "|     0 | 0       | 0        | 12.7     | 6.35    | 6.35    |  0       | 0       | 0       | 0        |\n",
      "|     1 | 0       | 0        |  0       | 0       | 0       | 25.4     | 0       | 0       | 0        |\n",
      "|     2 | 0       | 4.23333  |  4.23333 | 8.46667 | 0       |  4.23333 | 4.23333 | 0       | 0        |\n",
      "|     3 | 0       | 0.940741 |  3.76296 | 4.7037  | 8.46667 |  2.82222 | 1.88148 | 1.88148 | 0.940741 |\n",
      "|     4 | 1.42697 | 1.14157  |  4.2809  | 6.84944 | 4.2809  |  3.42472 | 2.56854 | 1.42697 | 0        |\n",
      "|     5 | 0       | 0        |  0       | 0       | 0       |  0       | 0       | 0       | 0        |\n",
      "|     6 | 0       | 0        |  0       | 0       | 0       |  0       | 0       | 0       | 0        |\n",
      "|     7 | 0       | 0        |  0       | 0       | 0       |  0       | 0       | 0       | 0        |\n",
      "|     8 | 0       | 0        |  0       | 0       | 0       |  0       | 0       | 0       | 0        |\n",
      "\n",
      "\n",
      "|   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |   6.0 |   7.0 |   8.0 |   9.0 |\n",
      "|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n",
      "|     0 |     0 |     0 |     2 |     1 |     1 |     0 |     0 |     0 |     0 |\n",
      "|     1 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |\n",
      "|     2 |     0 |     1 |     1 |     2 |     0 |     1 |     1 |     0 |     0 |\n",
      "|     3 |     0 |     1 |     4 |     5 |     9 |     3 |     2 |     2 |     1 |\n",
      "|     4 |     5 |     4 |    15 |    24 |    15 |    12 |     9 |     5 |     0 |\n",
      "|     5 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|     6 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|     7 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n",
      "|     8 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/SVM/linear.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/SVM/linear.pkl', 'rb') as f:\n",
    "        svrL = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a SVR (SVM Regression) model and train it on (X_train, y_train), kernel should be 'linear'\n",
    "    svrL = SVR(kernel='linear')\n",
    "    svrL.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/SVM/linear.pkl','wb') as f:\n",
    "        pickle.dump(svrL,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_svrL = np.rint(svrL.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_svrL).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrL, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrL), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |   2.0 |     3.0 |     4.0 |\n",
      "|----|-------|-------|-------|---------|---------|\n",
      "|  0 |     0 |     0 |     0 | 0       | 25.4    |\n",
      "|  1 |     0 |     0 |     0 | 0       | 25.4    |\n",
      "|  2 |     0 |     0 |     0 | 0       | 25.4    |\n",
      "|  3 |     0 |     0 |     0 | 2.82222 | 22.5778 |\n",
      "|  4 |     0 |     0 |     0 | 0       | 25.4    |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |\n",
      "|----|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     0 |     4 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     1 |\n",
      "|  2 |     0 |     0 |     0 |     0 |     6 |\n",
      "|  3 |     0 |     0 |     0 |     3 |    24 |\n",
      "|  4 |     0 |     0 |     0 |     0 |    89 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/SVM/rbf.pkl')):\n",
    "    # Load the random forest\n",
    "    print(\"Loaded\")\n",
    "    with open('../Models/SVM/rbf.pkl', 'rb') as f:\n",
    "        svrrbf = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a SVR (SVM Regression) model and train it on (X_train, y_train), kernel should be 'linear'\n",
    "    svrrbf = SVR(kernel='rbf')\n",
    "    svrrbf.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/SVM/rbf.pkl','wb') as f:\n",
    "        pickle.dump(svrrbf,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_svrrbf = np.rint(svrrbf.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_svrrbf).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrrbf, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrrbf), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |   2.0 |     3.0 |     4.0 |      5.0 |\n",
      "|----|-------|-------|-------|---------|---------|----------|\n",
      "|  0 |     0 |     0 |     0 | 0       | 25.4    | 0        |\n",
      "|  1 |     0 |     0 |     0 | 0       | 25.4    | 0        |\n",
      "|  2 |     0 |     0 |     0 | 0       | 25.4    | 0        |\n",
      "|  3 |     0 |     0 |     0 | 3.76296 | 21.637  | 0        |\n",
      "|  4 |     0 |     0 |     0 | 1.99775 | 23.1169 | 0.285393 |\n",
      "|  5 |     0 |     0 |     0 | 0       |  0      | 0        |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |\n",
      "|----|-------|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     0 |     4 |     0 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     1 |     0 |\n",
      "|  2 |     0 |     0 |     0 |     0 |     6 |     0 |\n",
      "|  3 |     0 |     0 |     0 |     4 |    23 |     0 |\n",
      "|  4 |     0 |     0 |     0 |     7 |    81 |     1 |\n",
      "|  5 |     0 |     0 |     0 |     0 |     0 |     0 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/SVM/poly_3.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/SVM/poly_3.pkl', 'rb') as f:\n",
    "        svrpoly_3 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a SVR (SVM Regression) model and train it on (X_train, y_train), kernel should be 'linear'\n",
    "    svrpoly_3 = SVR(kernel=\"poly\", degree=3)\n",
    "    svrpoly_3.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/SVM/poly_3.pkl','wb') as f:\n",
    "        pickle.dump(svrpoly_3,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_svrpoly_3 = np.rint(svrpoly_3.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_svrpoly_3).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrpoly_3, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrpoly_3), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |   2.0 |     3.0 |     4.0 |      5.0 |\n",
      "|----|-------|-------|-------|---------|---------|----------|\n",
      "|  0 |     0 |     0 |     0 | 0       | 25.4    | 0        |\n",
      "|  1 |     0 |     0 |     0 | 0       | 25.4    | 0        |\n",
      "|  2 |     0 |     0 |     0 | 0       | 25.4    | 0        |\n",
      "|  3 |     0 |     0 |     0 | 3.76296 | 21.637  | 0        |\n",
      "|  4 |     0 |     0 |     0 | 1.99775 | 23.1169 | 0.285393 |\n",
      "|  5 |     0 |     0 |     0 | 0       |  0      | 0        |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |\n",
      "|----|-------|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     0 |     4 |     0 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     1 |     0 |\n",
      "|  2 |     0 |     0 |     0 |     0 |     6 |     0 |\n",
      "|  3 |     0 |     0 |     0 |     4 |    23 |     0 |\n",
      "|  4 |     0 |     0 |     0 |     7 |    81 |     1 |\n",
      "|  5 |     0 |     0 |     0 |     0 |     0 |     0 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/SVM/poly_4.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/SVM/poly_4.pkl', 'rb') as f:\n",
    "        svrpoly_4 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a SVR (SVM Regression) model and train it on (X_train, y_train), kernel should be 'linear'\n",
    "    svrpoly_4 = SVR(kernel=\"poly\", degree=3)\n",
    "    svrpoly_4.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/SVM/poly_4.pkl','wb') as f:\n",
    "        pickle.dump(svrpoly_4,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_svrpoly_4 = np.rint(svrpoly_4.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_svrpoly_4).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrpoly_4, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_svrpoly_4), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |      2.0 |     3.0 |     4.0 |\n",
      "|----|-------|-------|----------|---------|---------|\n",
      "|  0 |     0 |     0 | 0        | 0       | 25.4    |\n",
      "|  1 |     0 |     0 | 0        | 0       | 25.4    |\n",
      "|  2 |     0 |     0 | 0        | 0       | 25.4    |\n",
      "|  3 |     0 |     0 | 0        | 1.88148 | 23.5185 |\n",
      "|  4 |     0 |     0 | 0.285393 | 1.42697 | 23.6876 |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |\n",
      "|----|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     0 |     4 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     1 |\n",
      "|  2 |     0 |     0 |     0 |     0 |     6 |\n",
      "|  3 |     0 |     0 |     0 |     2 |    25 |\n",
      "|  4 |     0 |     0 |     1 |     5 |    83 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/SVM/sigmoid.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/SVM/sigmoid.pkl', 'rb') as f:\n",
    "        sigmoid = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a SVR (SVM Regression) model and train it on (X_train, y_train), kernel should be 'linear'\n",
    "    sigmoid = SVR(kernel=\"sigmoid\")\n",
    "    sigmoid.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/SVM/sigmoid.pkl','wb') as f:\n",
    "        pickle.dump(sigmoid,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_sigmoid = np.rint(sigmoid.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_sigmoid).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_sigmoid, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_sigmoid), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "\n",
    "these are all regesors, maybe try classification?\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "     ---------------------------------------- 99.8/99.8 MB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages (from xgboost) (1.24.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |     2.0 |      3.0 |     4.0 |\n",
      "|----|-------|-------|---------|----------|---------|\n",
      "|  0 |     0 |     0 | 0       | 12.7     | 12.7    |\n",
      "|  1 |     0 |     0 | 0       | 25.4     |  0      |\n",
      "|  2 |     0 |     0 | 0       |  8.46667 | 16.9333 |\n",
      "|  3 |     0 |     0 | 1.88148 | 10.3481  | 13.1704 |\n",
      "|  4 |     0 |     0 | 1.14157 |  9.98876 | 14.2697 |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |\n",
      "|----|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     2 |     2 |\n",
      "|  1 |     0 |     0 |     0 |     1 |     0 |\n",
      "|  2 |     0 |     0 |     0 |     2 |     4 |\n",
      "|  3 |     0 |     0 |     2 |    11 |    14 |\n",
      "|  4 |     0 |     0 |     4 |    35 |    50 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/XGB/xgb_0.5.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/XGB/xgb_0.5.pkl', 'rb') as f:\n",
    "        xgb_reg2 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a xgb regression model and train it on (X_train, y_train)\n",
    "    xgb_reg2 = XGBRegressor(objective ='reg:squarederror', scale_pos_weight = .5)\n",
    "    xgb_reg2.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/XGB/xgb_0.5.pkl','wb') as f:\n",
    "        pickle.dump(xgb_reg2,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_xgb_reg2 = np.rint(xgb_reg2.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_xgb_reg2).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_xgb_reg2, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_xgb_reg2), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |     2.0 |      3.0 |      4.0 |\n",
      "|----|-------|-------|---------|----------|----------|\n",
      "|  0 |     0 |     0 | 6.35    |  0       | 19.05    |\n",
      "|  1 |     0 |     0 | 0       | 25.4     |  0       |\n",
      "|  2 |     0 |     0 | 4.23333 | 12.7     |  8.46667 |\n",
      "|  3 |     0 |     0 | 0       |  9.40741 | 15.9926  |\n",
      "|  4 |     0 |     0 | 0.85618 |  7.42022 | 17.1236  |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |\n",
      "|----|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     1 |     0 |     3 |\n",
      "|  1 |     0 |     0 |     0 |     1 |     0 |\n",
      "|  2 |     0 |     0 |     1 |     3 |     2 |\n",
      "|  3 |     0 |     0 |     0 |    10 |    17 |\n",
      "|  4 |     0 |     0 |     3 |    26 |    60 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/XGB/xgb_5.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/XGB/xgb_5.pkl', 'rb') as f:\n",
    "        xgb_reg2 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a xgb regression model and train it on (X_train, y_train)\n",
    "    xgb_reg2 = XGBRegressor(objective ='reg:squarederror', scale_pos_weight = 5)\n",
    "    xgb_reg2.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/XGB/xgb_5.pkl','wb') as f:\n",
    "        pickle.dump(xgb_reg2,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_xgb_reg2 = np.rint(xgb_reg2.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_xgb_reg2).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_xgb_reg2, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_xgb_reg2), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= Pred, Y= True\n",
      "|    |   0.0 |   1.0 |      2.0 |      3.0 |     4.0 |\n",
      "|----|-------|-------|----------|----------|---------|\n",
      "|  0 |     0 |     0 | 0        |  6.35    | 19.05   |\n",
      "|  1 |     0 |     0 | 0        |  0       | 25.4    |\n",
      "|  2 |     0 |     0 | 0        | 12.7     | 12.7    |\n",
      "|  3 |     0 |     0 | 0.940741 |  8.46667 | 15.9926 |\n",
      "|  4 |     0 |     0 | 1.71236  |  6.84944 | 16.8382 |\n",
      "\n",
      "\n",
      "|    |   0.0 |   1.0 |   2.0 |   3.0 |   4.0 |\n",
      "|----|-------|-------|-------|-------|-------|\n",
      "|  0 |     0 |     0 |     0 |     1 |     3 |\n",
      "|  1 |     0 |     0 |     0 |     0 |     1 |\n",
      "|  2 |     0 |     0 |     0 |     3 |     3 |\n",
      "|  3 |     0 |     0 |     1 |     9 |    17 |\n",
      "|  4 |     0 |     0 |     6 |    24 |    59 |\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('../Models/XGB/xgb_30.pkl')):\n",
    "    print(\"Loaded\")\n",
    "    # Load the random forest\n",
    "    with open('../Models/XGB/xgb_30.pkl', 'rb') as f:\n",
    "        xgb_reg2 = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    # Build a xgb regression model and train it on (X_train, y_train)\n",
    "    xgb_reg2 = XGBRegressor(objective ='reg:squarederror', scale_pos_weight = 30)\n",
    "    xgb_reg2.fit(X_train, y_train)\n",
    "\n",
    "    with open('../Models/XGB/xgb_30.pkl','wb') as f:\n",
    "        pickle.dump(xgb_reg2,f)\n",
    "\n",
    "# Test lin_reg on X_test\n",
    "pred_xgb_reg2 = np.rint(xgb_reg2.predict(X_test))\n",
    "headers = list(np.arange(np.unique(pred_xgb_reg2).max()+1))\n",
    "\n",
    "print(\"X= Pred, Y= True\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_xgb_reg2, sample_weight=compute_sample_weight('balanced', y_test)), headers=headers ,showindex=\"always\", tablefmt=\"github\"))\n",
    "print(\"\\n\")\n",
    "print(tabulate(confusion_matrix(y_test, pred_xgb_reg2), headers=headers ,showindex=\"always\", tablefmt=\"github\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
