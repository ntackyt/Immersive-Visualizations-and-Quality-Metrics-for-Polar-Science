{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rand Forest Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from sklearn.ensemble import ExtraTreesClassifier # for future work\n",
    "# from sklearn.tree import DecisionTreeClassifier # for future work\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, \n",
    "                            classification_report, multilabel_confusion_matrix, mean_squared_error, mean_absolute_error)\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995 ['Data_20120330_01_004_0', 'Data_20120330_01_004_1', 'Data_20120330_01_004_10', 'Data_20120330_01_004_11', 'Data_20120330_01_004_12']\n",
      "634\n",
      "634\n"
     ]
    }
   ],
   "source": [
    "# Load file names and labels for the processed data\n",
    "data_folder_prefix = \"../Seg_Featured_Data_Updated/Seg_Featured_\"\n",
    "\n",
    "with open(\"../data_labels.json\", 'r') as json_file:\n",
    "    label_dict = json.load(json_file)\n",
    "\n",
    "data_files = glob.glob(\"../Seg_Featured_Data_Updated/Seg_Featured_*\")\n",
    "avalible_files=[]\n",
    "for fl in data_files:\n",
    "    avalible_files.append(fl[len(\"../Seg_Featured_Data_Updated\\Seg_Featured_\"):-len(\".npy\")])\n",
    "\n",
    "print(len(avalible_files), avalible_files[:5])\n",
    "# print(avalible_files[0], list(label_dict.keys())[0])\n",
    "\n",
    "\n",
    "file_names = set.intersection(set(avalible_files), set(list(label_dict.keys())))\n",
    "print(len(file_names))\n",
    "\n",
    "labels = []\n",
    "for fl in file_names:\n",
    "    labels.append(label_dict[fl])\n",
    "print(len(labels))\n",
    "\n",
    "files = [data_folder_prefix+x+\".npy\" for x in file_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [ 20   6  22 120 466] [0.03154574 0.00946372 0.03470032 0.18927445 0.73501577]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7350157728706624"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct, values = np.unique(labels, return_counts=True)\n",
    "print(ct, values, values/values.sum())\n",
    "\n",
    "pred = [4]* len(files)\n",
    "accuracy_score(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2229,)\n",
      "(635, 2229)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((634, 2229), 634)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len([0]*576+[0]*576+[0]*576+[0]*250*2+[0]*1) \n",
    "flattened_test_load = np.zeros((max_len, ))\n",
    "print(flattened_test_load.shape)\n",
    "\n",
    "for fl in files:\n",
    "    data = np.load(fl, None, allow_pickle=True)\n",
    "    flattened_test_load = np.vstack((flattened_test_load, data))\n",
    "\n",
    "print(flattened_test_load.shape)\n",
    "\n",
    "flattened_data = flattened_test_load[1:,:]\n",
    "flattened_data.shape, len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507 127 507 127\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattened_data, labels, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [ 4  2 10 27 84] [0.03149606 0.01574803 0.07874016 0.21259843 0.66141732]\n"
     ]
    }
   ],
   "source": [
    "ct, values = np.unique(y_test, return_counts=True)\n",
    "print(ct, values, values/values.sum())\n",
    "\n",
    "pred = [4]* len(y_test)\n",
    "accuracy_score(y_test, pred)\n",
    "\n",
    "test_weights = values/values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc  MR  MP  MF1  MF1  MAE  MSE\n",
      " 0.6299212598425197 0.19047619047619047 0.13559322033898305 0.15841584158415842 0.5826771653543307 1.2125984251968505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.68      0.95      0.79        84\n",
      "\n",
      "    accuracy                           0.63       127\n",
      "   macro avg       0.14      0.19      0.16       127\n",
      "weighted avg       0.45      0.63      0.52       127\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [127, 127, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MF1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MF1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MAE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MSE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     12\u001b[0m     clf0\u001b[38;5;241m.\u001b[39mscore(X_test, y_test),\n\u001b[0;32m     13\u001b[0m     recall_score(y_test, pred_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     mean_squared_error(y_test, pred_labels)\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, pred_labels))\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_weights\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:338\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(sample_weight)\n\u001b[1;32m--> 338\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, None}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [127, 127, 5]"
     ]
    }
   ],
   "source": [
    "# create Random Forest\n",
    "clf0 = RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    max_depth=None,\n",
    "    min_samples_split=10, \n",
    "    class_weight='balanced'\n",
    "    )\n",
    "\n",
    "clf0.fit(X_train, y_train)\n",
    "pred_labels = clf0.predict(X_test)\n",
    "print('Acc',' MR',' MP',' MF1',' MF1',' MAE',' MSE\\n', \n",
    "    clf0.score(X_test, y_test),\n",
    "    recall_score(y_test, pred_labels, average='macro'),\n",
    "    precision_score(y_test, pred_labels, average='macro'),\n",
    "    f1_score(y_test, pred_labels,average='macro'),\n",
    "    mean_absolute_error(y_test, pred_labels),\n",
    "    mean_squared_error(y_test, pred_labels)\n",
    ")\n",
    "print(classification_report(y_test, pred_labels))\n",
    "print(confusion_matrix(y_test, pred_labels, sample_weight=compute_sample_weight('balanced', y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get accuracy\n",
    "# acc = clf0.score(X_test, y_test)\n",
    "\n",
    "# pred_labels = clf0.predict(X_test)\n",
    "\n",
    "# print('Acc:', acc,'\\nmR',recall_score(y_test, pred_labels, average='micro'),'\\nmP', precision_score(y_test, pred_labels, average='micro'),\n",
    "# '\\nMR',recall_score(y_test, pred_labels, average='macro'),'\\nMP', precision_score(y_test, pred_labels, average='macro'),\n",
    "# '\\nmF1',f1_score(y_test, pred_labels,average='micro'),'\\nMF1', f1_score(y_test, pred_labels,average='macro'))\n",
    "\n",
    "# # print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc  MR  MP  MF1  MF1  MAE  MSE\n",
      " 0.6377952755905512 0.2455026455026455 0.26004273504273506 0.23530916844349684 0.5433070866141733 1.078740157480315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.12      0.04      0.06        27\n",
      "           4       0.68      0.94      0.79        84\n",
      "\n",
      "    accuracy                           0.64       127\n",
      "   macro avg       0.26      0.25      0.24       127\n",
      "weighted avg       0.49      0.64      0.54       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [127, 127, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MF1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MF1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MAE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m MSE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     21\u001b[0m     clf_1\u001b[38;5;241m.\u001b[39mscore(X_test, y_test),\n\u001b[0;32m     22\u001b[0m     recall_score(y_test, pred_labels_1, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     mean_squared_error(y_test, pred_labels_1)\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, pred_labels_1))\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_weights\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:338\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(sample_weight)\n\u001b[1;32m--> 338\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, None}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [127, 127, 5]"
     ]
    }
   ],
   "source": [
    "# create Random Forest\n",
    "clf_1 = RandomForestClassifier(\n",
    "    n_estimators=1000, max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced'\n",
    "    )\n",
    "\n",
    "clf_1.fit(X_train, y_train)\n",
    "\n",
    "pred_labels_1 = clf_1.predict(X_test)\n",
    "\n",
    "# print('Acc',clf_1.score(X_test, y_test),\n",
    "# '\\nMR',recall_score(y_test, pred_labels_1, average='macro'),\n",
    "# '\\nMP', precision_score(y_test, pred_labels_1, average='macro'),\n",
    "# '\\nMF1', f1_score(y_test, pred_labels_1,average='macro'),\n",
    "# '\\nMAE', mean_absolute_error(y_test, pred_labels_1),\n",
    "# '\\nMSE', mean_squared_error(y_test, pred_labels_1)\n",
    "# )\n",
    "\n",
    "print('Acc',' MR',' MP',' MF1',' MF1',' MAE',' MSE\\n', \n",
    "    clf_1.score(X_test, y_test),\n",
    "    recall_score(y_test, pred_labels_1, average='macro'),\n",
    "    precision_score(y_test, pred_labels_1, average='macro'),\n",
    "    f1_score(y_test, pred_labels_1,average='macro'),\n",
    "    mean_absolute_error(y_test, pred_labels_1),\n",
    "    mean_squared_error(y_test, pred_labels_1)\n",
    ")\n",
    "print(classification_report(y_test, pred_labels_1))\n",
    "print(confusion_matrix(y_test, pred_labels_1, sample_weight=compute_sample_weight('balanced', y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc  MR  MP  MF1  MF1  MAE  MSE\n",
      " 0.6299212598425197 0.23809523809523808 0.20405797101449274 0.21593682699210343 0.5511811023622047 1.0551181102362204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.69      0.94      0.79        84\n",
      "\n",
      "    accuracy                           0.63       127\n",
      "   macro avg       0.20      0.24      0.22       127\n",
      "weighted avg       0.46      0.63      0.53       127\n",
      "\n",
      "[[ 1  0  0  1  2]\n",
      " [ 0  0  0  2  0]\n",
      " [ 0  0  0  1  9]\n",
      " [ 2  0  0  0 25]\n",
      " [ 0  0  0  5 79]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# create Random Forest\n",
    "clf_2 = RandomForestClassifier(\n",
    "    n_estimators=1000, max_depth=None,\n",
    "    min_samples_split=20,\n",
    "    class_weight='balanced'\n",
    "    )\n",
    "\n",
    "clf_2.fit(X_train, y_train)\n",
    "pred_labels_2 = clf_2.predict(X_test)\n",
    "\n",
    "# print('Acc',clf_2.score(X_test, y_test),\n",
    "# '\\nMR',recall_score(y_test, pred_labels_2, average='macro'),\n",
    "# '\\nMP', precision_score(y_test, pred_labels_2, average='macro'),\n",
    "# '\\nMF1', f1_score(y_test, pred_labels_2,average='macro'),\n",
    "# '\\nMAE', mean_absolute_error(y_test, pred_labels_2),\n",
    "# '\\nMSE', mean_squared_error(y_test, pred_labels_2)\n",
    "# )\n",
    "\n",
    "print('Acc',' MR',' MP',' MF1',' MF1',' MAE',' MSE\\n', \n",
    "    clf_2.score(X_test, y_test),\n",
    "    recall_score(y_test, pred_labels_2, average='macro'),\n",
    "    precision_score(y_test, pred_labels_2, average='macro'),\n",
    "    f1_score(y_test, pred_labels_2,average='macro'),\n",
    "    mean_absolute_error(y_test, pred_labels_2),\n",
    "    mean_squared_error(y_test, pred_labels_2)\n",
    ")\n",
    "\n",
    "print(classification_report(y_test, pred_labels_2))\n",
    "\n",
    "print(confusion_matrix(y_test, pred_labels_2, sample_weight=compute_sample_weight('balanced', y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc  MR  MP  MF1  MF1  MAE  MSE\n",
      " 0.6377952755905512 0.24047619047619045 0.20112044817927172 0.2147783251231527 0.5669291338582677 1.1811023622047243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.67      0.95      0.79        84\n",
      "\n",
      "    accuracy                           0.64       127\n",
      "   macro avg       0.20      0.24      0.21       127\n",
      "weighted avg       0.46      0.64      0.53       127\n",
      "\n",
      "[[ 1  0  0  0  3]\n",
      " [ 0  0  0  0  2]\n",
      " [ 0  0  0  1  9]\n",
      " [ 2  0  0  0 25]\n",
      " [ 0  0  0  4 80]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# create Random Forest\n",
    "clf_3 = RandomForestClassifier(\n",
    "    n_estimators=10000, max_depth=5000,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced'\n",
    "    )\n",
    "\n",
    "clf_3.fit(X_train, y_train)\n",
    "pred_labels_3 = clf_3.predict(X_test)\n",
    "\n",
    "# print('Acc',clf_3.score(X_test, y_test),\n",
    "# '\\nMR',recall_score(y_test, pred_labels_3, average='macro'),\n",
    "# '\\nMP', precision_score(y_test, pred_labels_3, average='macro'),\n",
    "# '\\nMF1', f1_score(y_test, pred_labels_3,average='macro'),\n",
    "# '\\nMAE', mean_absolute_error(y_test, pred_labels_3),\n",
    "# '\\nMSE', mean_squared_error(y_test, pred_labels_3)\n",
    "# )\n",
    "print('Acc',' MR',' MP',' MF1',' MF1',' MAE',' MSE\\n', \n",
    "    clf_3.score(X_test, y_test),\n",
    "    recall_score(y_test, pred_labels_3, average='macro'),\n",
    "    precision_score(y_test, pred_labels_3, average='macro'),\n",
    "    f1_score(y_test, pred_labels_3,average='macro'),\n",
    "    mean_absolute_error(y_test, pred_labels_3),\n",
    "    mean_squared_error(y_test, pred_labels_3)\n",
    ")\n",
    "print(classification_report(y_test, pred_labels_3))\n",
    "print(confusion_matrix(y_test, pred_labels_3, sample_weight=compute_sample_weight('balanced', y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc  MR  MP  MF1  MF1  MAE  MSE\n",
      " 0.6377952755905512 0.19788359788359786 0.16175213675213676 0.17063255152807394 0.5590551181102362 1.110236220472441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.12      0.04      0.06        27\n",
      "           4       0.68      0.95      0.80        84\n",
      "\n",
      "    accuracy                           0.64       127\n",
      "   macro avg       0.16      0.20      0.17       127\n",
      "weighted avg       0.48      0.64      0.54       127\n",
      "\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 4.25196850e-01\n",
      "  1.32283465e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.12598425e-01\n",
      "  6.61417323e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.12598425e-01\n",
      "  5.95275591e+00]\n",
      " [3.14960630e-02 0.00000000e+00 0.00000000e+00 2.12598425e-01\n",
      "  1.65354331e+01]\n",
      " [0.00000000e+00 0.00000000e+00 7.87401575e-02 6.37795276e-01\n",
      "  5.29133858e+01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\naomi\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# create Random Forest\n",
    "clf_4 = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced'\n",
    "    )\n",
    "\n",
    "clf_4.fit(X_train, y_train)\n",
    "pred_labels_4 = clf_4.predict(X_test)\n",
    "\n",
    "# print('Acc',clf_4.score(X_test, y_test),\n",
    "# '\\nMR',recall_score(y_test, pred_labels_4, average='macro'),\n",
    "# '\\nMP', precision_score(y_test, pred_labels_4, average='macro'),\n",
    "# '\\nMF1', f1_score(y_test, pred_labels_4,average='macro'),\n",
    "# '\\nMAE', mean_absolute_error(y_test, pred_labels_4),\n",
    "# '\\nMSE', mean_squared_error(y_test, pred_labels_4)\n",
    "# )\n",
    "print('Acc',' MR',' MP',' MF1',' MF1',' MAE',' MSE\\n', \n",
    "    clf_4.score(X_test, y_test),\n",
    "    recall_score(y_test, pred_labels_4, average='macro'),\n",
    "    precision_score(y_test, pred_labels_4, average='macro'),\n",
    "    f1_score(y_test, pred_labels_4,average='macro'),\n",
    "    mean_absolute_error(y_test, pred_labels_4),\n",
    "    mean_squared_error(y_test, pred_labels_4)\n",
    ")\n",
    "\n",
    "print(classification_report(y_test, pred_labels_4))\n",
    "# print(confusion_matrix(y_test, pred_labels_4)* test_weights)\n",
    "print(confusion_matrix(y_test, pred_labels_4, sample_weight=compute_sample_weight('balanced', y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
