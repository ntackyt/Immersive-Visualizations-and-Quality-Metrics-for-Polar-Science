{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fec931",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "     -------------------------------------- 300.8/300.8 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 44.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda2\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\anaconda2\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.3-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 26.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda2\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.3.0)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Downloading numpy-1.26.2-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     --------------------------------------- 15.8/15.8 MB 31.2 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 31.4 MB/s eta 0:00:00\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 53.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda2\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     ---------------------------------------- 130.2/130.2 kB ? eta 0:00:00\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "     ------------------------------------- 938.4/938.4 kB 29.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "     ------------------------------------- 442.0/442.0 kB 27.0 MB/s eta 0:00:00\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     --------------------------------------- 24.4/24.4 MB 31.2 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda2\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda2\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl (413 kB)\n",
      "     ------------------------------------- 413.4/413.4 kB 25.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.24.0-py2.py3-none-any.whl (183 kB)\n",
      "     ------------------------------------- 183.8/183.8 kB 11.6 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "     ------------------------------------- 422.5/422.5 kB 25.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda2\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, opt-einsum, ml-dtypes, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.24.0 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.59.3 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 numpy-1.26.2 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.2 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005a53ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv--python\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "     --------------------------------------- 38.1/38.1 MB 25.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\anaconda2\\lib\\site-packages (from opencv--python) (1.26.2)\n",
      "Installing collected packages: opencv--python\n",
      "Successfully installed opencv--python-4.8.1.78\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv--python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f6ada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35785de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\250x250\n"
     ]
    }
   ],
   "source": [
    "%cd \"D://250x250//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7966e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743\n",
      "743\n",
      "(62507,)\n",
      "(744, 62507) (62507,) num padded: 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((743, 62507), 743)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"D://Downloads//250x250\"\n",
    "# Load file names and labels for the processed data\n",
    "data_folder_prefix = \"Seg_Featured_Data/Seg_Featured_\"\n",
    "\n",
    "with open(\"data_labels.json\", 'r') as json_file:\n",
    "    label_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "file_names = list(label_dict.keys())\n",
    "print(len(file_names))\n",
    "\n",
    "labels = []\n",
    "for fl in file_names:\n",
    "    labels.append(label_dict[fl])\n",
    "print(len(labels))\n",
    "test_load = np.load(\"D://Downloads//test0.npy\", None, allow_pickle=True)\n",
    "test_load.shape\n",
    "\n",
    "files = [\"Seg_Featured_\"+x+\".npy\" for x in file_names]\n",
    "# files = glob.glob(\"Seg_Featured_Data/*.npy\")\n",
    "# files = glob.glob(\"Seg_Featured_Data/*.npy\")\n",
    "max_len = 250*250+7\n",
    "num_padded = 0\n",
    "flattened_test_load = np.zeros((max_len, ))\n",
    "print(flattened_test_load.shape)\n",
    "\n",
    "for fl in files:\n",
    "    test_load = np.load(fl, None, allow_pickle=True)\n",
    "    y,x,_ = test_load.shape\n",
    "    # Ignore depth 0\n",
    "    # Keep all Depth 1\n",
    "    #  if the x,y is less than 250x50 pad w 0s\n",
    "    layers_depth = test_load[:,:,1]\n",
    "    # print(layers_depth.shape)\n",
    "    if x < 250:\n",
    "        layers_depth = np.hstack((layers_depth, np.zeros((y, y-x))))\n",
    "        num_padded +=1\n",
    "    if y < 250:\n",
    "        layers_depth = np.hstack((layers_depth, np.zeros((250-y, 250))))\n",
    "    layers_depth = layers_depth.flatten()\n",
    "    # Get the metrics from the other depths\n",
    "    vl, ct = np.unique(test_load[:,:,5], return_counts=True)\n",
    "    if len(ct)>1:\n",
    "        num_bp = ct[1]\n",
    "    else:\n",
    "        num_bp = 0\n",
    "    # print(\"conected components (mean, std)\", np.mean(test_load[:y//10-1,:x//10-1,2]), np.std(test_load[:y//10-1,:x//10-1,2]))\n",
    "    # print(\"orientaiton (mean, std)\", np.mean(test_load[:y//10-1,:x//10-1,3]), np.std(test_load[:y//10-1,:x//10-1,3]))\n",
    "    # print(\"mean orientaiton (mean, std)\", np.mean(test_load[:250//10-1,:250//10-1,4]), np.std(test_load[:250//10-1,:250//10-1,4]))\n",
    "    # print(\"num breakpoints\",num_bp)\n",
    "    # print(\"dist map (mean, std)\", np.mean(test_load[:,:,6]), np.std(test_load[:,:,6]))\n",
    "    data= np.append(layers_depth, [np.mean(test_load[:y//10-1,:x//10-1,2]), np.std(test_load[:y//10-1,:x//10-1,2]),\n",
    "                                    np.mean(test_load[:y//10-1,:x//10-1,3]), np.std(test_load[:y//10-1,:x//10-1,3]),\n",
    "                                    num_bp,\n",
    "                                    np.mean(test_load[:,:,6]), np.std(test_load[:,:,6])])\n",
    "\n",
    "    # print(data.shape)\n",
    "    flattened_test_load = np.vstack((flattened_test_load, data))\n",
    "print(flattened_test_load.shape,flattened_test_load[0].shape, \"num padded:\", num_padded)\n",
    "flattened_data = flattened_test_load[1:,:]\n",
    "flattened_data.shape, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445335a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattened_data, labels, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d0723e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda2\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=62507, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea1e1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128,input_dim=62507,activation='relu'))\n",
    "model2.add(Dense(64,activation='relu'))\n",
    "model2.add(Dense(32,activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c59b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(256,input_dim=62507,activation='relu'))\n",
    "model3.add(Dense(128,activation='relu'))\n",
    "model3.add(Dense(64,activation='relu'))\n",
    "model3.add(Dense(32,activation='relu'))\n",
    "model3.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addfaa49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda2\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066a0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45953f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbff6a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Anaconda2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda2\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "19/19 [==============================] - 2s 37ms/step - loss: 3.2483 - accuracy: 0.0421\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 3.0240 - accuracy: 0.0539\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.6079 - accuracy: 0.0657\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.5181 - accuracy: 0.0623\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2993 - accuracy: 0.0673\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2503 - accuracy: 0.0673\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.1667 - accuracy: 0.0673\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.2024 - accuracy: 0.0673\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.3687 - accuracy: 0.0673\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.4943 - accuracy: 0.0673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19994ac9340>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff9bd77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 2s 69ms/step - loss: 4.0346\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 1s 68ms/step - loss: 2.7470\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 1s 69ms/step - loss: 1.1341\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 1s 69ms/step - loss: 0.7811\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 1s 69ms/step - loss: 0.5161\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 1s 68ms/step - loss: 0.2346\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 1s 68ms/step - loss: 0.0991\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 1s 68ms/step - loss: 0.0441\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 1s 67ms/step - loss: 0.0347\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 1s 67ms/step - loss: 0.0266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x199a1ce43a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd3c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 139ms/step - loss: 5.8408\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 1.9100\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.7247\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.4650\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.3204\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.1714\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0898\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0526\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0294\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x199a1e41bb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train,y_train,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035f046e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f47d297a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict(X_test)\n",
    "pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892b688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict(X_test)\n",
    "pred3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c34448b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2080536912751678\n",
      "0.17159361196058442\n",
      "0.2080536912751678\n",
      "0.19297746021883955\n",
      "0.2080536912751678\n",
      "2.6203861268068978\n",
      "1.3188219953503384\n",
      "0.2080536912751678\n",
      "0.13650600900145526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_test,np.rint(pred),average=\"micro\"))\n",
    "print(metrics.precision_score(np.rint(pred),y_test,average=\"macro\"))\n",
    "print(metrics.recall_score(np.rint(pred),y_test,average=\"micro\"))\n",
    "print(metrics.recall_score(np.rint(pred),y_test,average=\"macro\"))\n",
    "print(metrics.accuracy_score(np.rint(pred),y_test))\n",
    "print(metrics.mean_squared_error(y_test,pred))\n",
    "print(metrics.mean_absolute_error(y_test,pred))\n",
    "print(metrics.f1_score(y_test,np.rint(pred),average=\"micro\"))\n",
    "print(metrics.f1_score(y_test,np.rint(pred),average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21126750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2348993288590604\n",
      "0.27157055482743553\n",
      "0.2348993288590604\n",
      "0.2348993288590604\n",
      "0.19297746021883955\n",
      "2.23684118153881\n",
      "1.276738361224232\n",
      "0.2348993288590604\n",
      "0.196790403009979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_test,np.rint(pred2),average=\"micro\"))\n",
    "print(metrics.precision_score(np.rint(pred2),y_test,average=\"macro\"))\n",
    "print(metrics.recall_score(np.rint(pred2),y_test,average=\"micro\"))\n",
    "print(metrics.accuracy_score(np.rint(pred2),y_test))\n",
    "print(metrics.recall_score(np.rint(pred),y_test,average=\"macro\"))\n",
    "print(metrics.mean_squared_error(y_test,pred2))\n",
    "print(metrics.mean_absolute_error(y_test,pred2))\n",
    "print(metrics.f1_score(y_test,np.rint(pred2),average=\"micro\"))\n",
    "print(metrics.f1_score(y_test,np.rint(pred2),average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de7f956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24161073825503357\n",
      "0.24574049803407602\n",
      "0.24161073825503357\n",
      "0.2596070148489503\n",
      "0.24161073825503357\n",
      "2.069403368817958\n",
      "1.197907934652879\n",
      "0.24161073825503357\n",
      "0.1948170935040683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_test,np.rint(pred3),average=\"micro\"))\n",
    "print(metrics.precision_score(np.rint(pred3),y_test,average=\"macro\"))\n",
    "print(metrics.recall_score(np.rint(pred3),y_test,average=\"micro\"))\n",
    "print(metrics.recall_score(np.rint(pred3),y_test,average=\"macro\"))\n",
    "print(metrics.accuracy_score(np.rint(pred3),y_test))\n",
    "print(metrics.mean_squared_error(y_test,pred3))\n",
    "print(metrics.mean_absolute_error(y_test,pred3))\n",
    "print(metrics.f1_score(y_test,np.rint(pred3),average=\"micro\"))\n",
    "print(metrics.f1_score(y_test,np.rint(pred3),average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
